{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Dataset\n",
        "\n",
        "You can download the dataset from {https://darwin.v7labs.com/v7-labs/covid-19-chest-x-ray-dataset?sort=priority\\%3Adesc}.\n",
        "The data entitled as '`darwin dataset pull v7-labs/covid-19-chest-x-ray-dataset:all-images`' will be used in this assignment. All dataset consist of 6504 images from 702 classes. We will extract the images of 4 classes (Bacterial Pneumonia, Viral Pneumonia, No Pneumonia (healthy), Covid-19) and save them as .npy file with the following code:"
      ],
      "metadata": {
        "id": "xveQIshNWYdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "# importing modules\n",
        "import urllib.request\n",
        "from PIL import Image\n",
        "from keras import layers, models\n",
        "import tensorflow as tf\n",
        "\n",
        "# all-images file should be uploaded to the same file\n",
        "imageNames = glob.glob(\".../all-images/*\")\n",
        "\n",
        "dataset = []\n",
        "labels = []\n",
        "\n",
        "for i, imName in enumerate(imageNames):\n",
        "\n",
        "    # Opening JSON file\n",
        "    f = open(imName)\n",
        "    data = json.load(f)\n",
        "    for j in range(len(data['annotations'])):\n",
        "\n",
        "        if 'COVID-19' in (data['annotations'][j]['name']):\n",
        "          #load images from url    \n",
        "            urllib.request.urlretrieve(data['image']['url'],\"img.png\")    \n",
        "            img = Image.open(\"img.png\")\n",
        "            #convert images to grayscale\n",
        "            imgGray = img.convert('L')\n",
        "            #resize the image (156x156)\n",
        "            im = imgGray.resize((156,156), Image.LANCZOS)           \n",
        "            label = data['annotations'][j]['name']\n",
        "            dataset.append(np.array(im))\n",
        "            labels.append(label)\n",
        "            print(label)\n",
        "            break\n",
        "\n",
        "        if 'Viral Pneumonia' in (data['annotations'][j]['name']) \\\n",
        "            or 'Bacterial Pneumonia' in (data['annotations'][j]['name']) \\\n",
        "            or 'No Pneumonia (healthy)' in (data['annotations'][j]['name']):\n",
        "            #load images from url    \n",
        "            urllib.request.urlretrieve(data['image']['url'],\"img.png\")    \n",
        "            img = Image.open(\"img.png\")\n",
        "            #convert images to grayscale\n",
        "            imgGray = img.convert('L')\n",
        "            #resize the image (156x156)\n",
        "            im = imgGray.resize((156,156), Image.LANCZOS)           \n",
        "            label = data['annotations'][j]['name']\n",
        "            dataset.append(np.array(im))\n",
        "            labels.append(label)\n",
        "            break\n",
        "\n",
        "#Convert data shape of (n_of_samples, width, height, 1)\n",
        "dataset = np.dstack(dataset)    \n",
        "dataset = np.rollaxis(dataset,-1)\n",
        "labels = np.array(labels)\n",
        "\n",
        "#convert images gray scale to rgb\n",
        "data = np.array(layers.Lambda(tf.image.grayscale_to_rgb)(tf.expand_dims(dataset, -1)))\n",
        "\n",
        "# save data and labels into a folder\n",
        "np.save(\".../data.npy\", data)\n",
        "np.save(\".../labels.npy\", labels)"
      ],
      "metadata": {
        "id": "I6bqTVRSs-sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you save your data, you can load it from your directory."
      ],
      "metadata": {
        "id": "Dn3sH7yJWboe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "data = np.load('.../data.npy')\n",
        "labels = np.load('.../labels.npy')"
      ],
      "metadata": {
        "id": "b6ZPDhVLWbyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing Steps\n",
        "\n"
      ],
      "metadata": {
        "id": "B1b7dP-VbJpC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting Data"
      ],
      "metadata": {
        "id": "xC_YmdQMbn1K"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xStbdJAHblFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalize Data"
      ],
      "metadata": {
        "id": "R-r4ta3MbKLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LeplL77mbKS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Baseline Model"
      ],
      "metadata": {
        "id": "YONVgtOAbKca"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LhUlV9UNbKiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyze the performance of the baseline model"
      ],
      "metadata": {
        "id": "zOFuKRShbvTU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "58gf79ODcFPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adapting/fine-tuning the network"
      ],
      "metadata": {
        "id": "gnxtO6BIb3_P"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oiDja0Mub4YW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning"
      ],
      "metadata": {
        "id": "CBGr0x8ZcFn9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fn_WnCfDcFyD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}